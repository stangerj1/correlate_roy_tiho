{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accepted-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tropical-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dask_gateway import Gateway\n",
    "# from dask.distributed import Client\n",
    "# gateway = Gateway()\n",
    "# cluster = gateway.new_cluster()\n",
    "# cluster.adapt()\n",
    "# client = Client(cluster)\n",
    "# cluster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-statement",
   "metadata": {},
   "source": [
    "# Find coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "distinguished-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alert-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load datasets as xarrays\n",
    "roy_in = xr.open_dataset('/home/jovyan/roy and tk data/roy_data.nc')\n",
    "tk_in = xr.open_dataset('/home/jovyan/roy and tk data/tk_data.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "applied-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\n",
    "          \"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lasting-cowboy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "12.0\n"
     ]
    }
   ],
   "source": [
    "print(4320/360) # 12 points in each degree longitude\n",
    "print(2160/180) # 12 points in each degree latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "organizational-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onanmeanongitude, a for latitude\n",
    "# l for lowbound h for highbound\n",
    "o_l = 100 # longitude low bound \n",
    "o_h = 4300 # lon high\n",
    "a_l = 100 # lat low\n",
    "a_h = 2100 # lat high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aging-seattle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roy_in.sel(year=0).to_array()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "greatest-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year =  1\n",
      "year =  2\n",
      "year =  3\n",
      "year =  4\n",
      "year =  5\n"
     ]
    }
   ],
   "source": [
    "# convert both xarray datasets to 3d numpy arrays\n",
    "years = len(roy_in.year)\n",
    "\n",
    "for i in range(years): # for each year\n",
    "    \n",
    "    # create temporary list of arrays for each year\n",
    "    # 12 arrays in list for each year\n",
    "    # slices of global determined earlier are array bounds for each array\n",
    "    # arrays are numpy so months found through index not var identifier\n",
    "    roy_temp = roy_in.sel(year = i).to_array()[:,o_l:o_h,a_l:a_h]\n",
    "    tk_temp = tk_in.sel(year = i).to_array()[:,o_l:o_h,a_l:a_h]\n",
    "    print('year = ', i+1) # for checking progress\n",
    "\n",
    "    for j in range(len(months)): # each month within each year\n",
    "        \n",
    "                \n",
    "        if i == 0 and j == 0: # year 1 month 1: initiating array\n",
    "            roy_array = roy_temp[j] # one array for each dataset\n",
    "            tk_array = tk_temp[j]\n",
    "        \n",
    "        elif i == 0 and j == 1: # year 1 month 2: adding 2d array to 3d\n",
    "            roy_array = np.stack((roy_array,roy_temp[j])) # stack 2 2d \n",
    "            tk_array = np.stack((tk_array,tk_temp[j])) # creates 3d arrays\n",
    "        \n",
    "        else: # add further 2d arrays to 3d array\n",
    "\n",
    "            roy_array = np.concatenate((roy_array,[roy_temp[j]]))\n",
    "            tk_array = np.concatenate((tk_array,[tk_temp[j]]))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "minor-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "point___roy_________________tk______________\n",
      "0      62.444264444469596   223.0915653118241\n",
      "1      61.026244538904116   186.51807964035484\n",
      "2      68.19501724384746   177.91775686606374\n",
      "3      87.71085559841585   192.62805743126106\n",
      "4      124.84093032963813   211.68413497847737\n",
      "5      98.92517932821211   246.3580401197868\n",
      "6      125.12192460203273   227.95838747944484\n",
      "7      139.31264744010087   244.83402205183484\n",
      "8      101.89966119702062   215.3527976502453\n",
      "9      79.55075377305181   195.74980114146436\n",
      "10      64.3459923076707   186.35702408268367\n",
      "11      67.19546684064446   185.19846714458998\n",
      "12      61.04649344446801   222.6415142892931\n",
      "13      65.40708031098654   224.51498115229253\n",
      "14      64.17885248980478   197.23290070630796\n",
      "15      85.13885353195587   206.0085605769529\n",
      "16      130.56092456318868   242.97231505848313\n",
      "17      107.82664807173916   264.5114382843216\n",
      "18      113.90273087091302   252.76936745480882\n",
      "19      132.14368155900104   270.833891699752\n",
      "20      111.31530687067676   241.10370038634153\n",
      "21      81.9380337220624   210.93118066589085\n",
      "22      63.04355264480323   200.89131413523572\n",
      "23      65.23785481583141   212.00248465599037\n",
      "24      65.46973236081642   207.41321548640823\n",
      "25      59.71623461960103   208.01959739464738\n",
      "26      66.04175276594258   203.3646257145575\n",
      "27      81.99506295006054   206.04433572400205\n",
      "28      120.66361689256098   243.40427400742433\n",
      "29      107.87248047923923   263.3167461791053\n",
      "30      150.83556576984878   273.6474343575828\n",
      "31      132.8928318025188   258.37494250319526\n",
      "32      111.65206622929546   237.840648657667\n",
      "33      85.70798486004779   217.43962696536923\n",
      "34      66.70787391368481   206.17474155998087\n",
      "35      66.34590775074706   216.45161470821478\n",
      "36      62.80227183983131   227.57516900979203\n",
      "37      63.51023549564757   223.55686479836746\n",
      "38      62.76350574622827   201.7067530867345\n",
      "39      100.78908123255925   210.62888839643034\n",
      "40      130.23085231135286   235.70358836380646\n",
      "41      109.55112056836789   255.10984762381958\n",
      "42      129.81158281001035   270.5413501865623\n",
      "43      139.72882956998583   259.1463040896607\n",
      "44      99.01372546440132   227.07844938684258\n",
      "45      77.44419947930214   207.3165321644707\n",
      "46      67.29441475893047   202.7408901819471\n",
      "47      62.26900186565167   214.58662151688108\n",
      "48      61.81228740193858   216.35759719473933\n",
      "49      60.92366253925443   208.51900559364444\n",
      "50      67.21843556977716   191.94752603279596\n",
      "51      85.26529218504173   209.38765643258586\n",
      "52      124.0963062692409   234.62969486987356\n",
      "53      128.7154894120997   273.68768485601447\n",
      "54      164.0267203325949   278.1692569345967\n",
      "55      156.56478455253944   265.60714675540663\n",
      "56      99.79672714023762   227.1747812800707\n",
      "57      80.67591414875331   203.46327377968865\n",
      "58      62.48279012632951   197.68666811444282\n",
      "59      57.3301686577608   200.06818331995248\n"
     ]
    }
   ],
   "source": [
    "# remove outliers from both arrays\n",
    "# done on basis of each time step (60 total) rather than entire array\n",
    "\n",
    "print('point___roy_________________tk______________') # for showing maxs\n",
    "\n",
    "for i in range(len(roy_array)): # through each timestep\n",
    "    \n",
    "    max_roy = np.nanpercentile(roy_array[i],99) # find limit of 99th percentile\n",
    "    max_tk = np.nanpercentile(tk_array[i],99) # done on both arrays\n",
    "    \n",
    "    print(i,'    ',max_roy,' ',max_tk) # for showing values\n",
    "    \n",
    "    # in each array, in the given z value (timestep)\n",
    "    # for values in array less than max, preserve original value\n",
    "    # otherwise replace with nan value\n",
    "    roy_array[i] = np.where(roy_array[i]<max_roy,roy_array[i],np.nan)\n",
    "    tk_array[i] = np.where(tk_array[i]<max_tk,tk_array[i],np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indoor-brake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roy_in.Dec.sel(year=1).values[500:514,500:515]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "enormous-witness",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check no negative values\n",
    "#success: no negatives!\n",
    "\n",
    "# for i in range(len(roy_in.year)):\n",
    "#     display(np.amin(roy_in.sel(year=i)))\n",
    "#     display(np.amin(tk_in.sel(year=i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "extreme-daily",
   "metadata": {},
   "outputs": [],
   "source": [
    "#below doesnt work for some reason (only on tk)\n",
    "#xr.where(tk_in<max_tk,tk_in,np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-solid",
   "metadata": {},
   "source": [
    "# For correlation of entire map\n",
    "ignore until next title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten 3d arrays to 1d for correlation\n",
    "roy_flat = np.ndarray.flatten(roy_array[:])\n",
    "tk_flat = np.ndarray.flatten(tk_array[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe (starts 2 by pixel number times 60)\n",
    "combine = [roy_flat,tk_flat]\n",
    "df = pd.DataFrame(combine,index=['roy','tk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "enormous-collar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must transpose the matrix to be pixels by datasets for correlation\n",
    "# calculate correlation matrix\n",
    "df = df.transpose()\n",
    "corr_mat = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sharing-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse of coefficient\n",
    "coef = corr_mat.values[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-shopping",
   "metadata": {},
   "source": [
    "## Working with coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "reduced-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_roy = coef * roy_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "broke-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(roy_in.Jan.sel(year=0)[500:505,500:505])\n",
    "# display(coef * 16.15)\n",
    "# k_roy.Jan.sel(year=0)[500:505,500:505]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "legendary-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_array = coef * roy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "romantic-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = tk_array - k_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-fellow",
   "metadata": {},
   "source": [
    "# correlations for each pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "demographic-speech",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "lon_size = roy_array.shape[1]\n",
    "lat_size = roy_array.shape[2]\n",
    "\n",
    "print(lon_size)\n",
    "print(lat_size)\n",
    "\n",
    "corr_array = np.zeros((lon_size,lat_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 %\n",
      "1.1904761904761905 %\n",
      "2.380952380952381 %\n",
      "3.571428571428571 %\n",
      "4.761904761904762 %\n",
      "5.952380952380952 %\n",
      "7.142857142857142 %\n",
      "8.333333333333332 %\n"
     ]
    }
   ],
   "source": [
    "#in our 3d array we want to create a correlation coefficient for each (x,y) pixel value\n",
    "#we can use df.corr along z axis for each (x,y) value\n",
    "\n",
    "for i in range(lon_size):\n",
    "\n",
    "    if np.mod(i,50) == 0:\n",
    "        print((i/lon_size)*100,'%')   \n",
    "        \n",
    "    for j in range(lat_size):\n",
    "        \n",
    "        roy_z = roy_array[:,i,j] #absorption\n",
    "        tk_z = tk_array[:,i,j] #backscattering\n",
    "        \n",
    "        z_combined = [roy_z,tk_z]\n",
    "        corr_df = pd.DataFrame(z_combined,index = ['roy','tk'])\n",
    "        corr_df = corr_df.transpose()\n",
    "        \n",
    "        corr_array[i,j] = corr_df.corr().values[0,1]  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-defense",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to remove seasonality average each month over years (12 step time series)\n",
    "# look into regressoin coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_array = np.transpose(corr_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(corr_array)\n",
    "plt.colorbar()\n",
    "plt.savefig('/home/jovyan/quickplots/roy_tk_['\n",
    "            +str(o_l)+'-'+str(o_h)+','\n",
    "            +str(a_l)+'-'+str(a_h)+\n",
    "            '].png', dpi=600,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-hostel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(corr_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-spokesman",
   "metadata": {},
   "source": [
    "# Remove seasonality influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "further-feeling",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_size = roy_array.shape[1]\n",
    "lat_size = roy_array.shape[2]\n",
    "\n",
    "print(lon_size)\n",
    "print(lat_size)\n",
    "\n",
    "corr_array = np.zeros((lon_size,lat_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "roy_season = np.zeros((len(months),lon_size, lat_size))\n",
    "tk_season = np.zeros((len(months),lon_size, lat_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = np.zeros((5,12))\n",
    "\n",
    "for i in range(years):\n",
    "    groups[i] = np.arange((12*i),(12*(i+1)))\n",
    "\n",
    "    \n",
    "groups = np.transpose(groups)\n",
    "groups = np.array(groups, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "roy_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roy_grouping = roy_array[groups,i,j]\n",
    "\n",
    "# display(roy_array[groups,i,j])\n",
    "# display(roy_array[:,i,j])\n",
    "# display(np.nanmean(roy_grouping,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(lon_size):\n",
    "    \n",
    "    for j in range(lat_size):\n",
    "        \n",
    "        roy_grouping = roy_array[groups,i,j]\n",
    "        tk_grouping = tk_array[groups,i,j]\n",
    "        \n",
    "        roy_season[:,i,j] = np.nanmean(roy_grouping,axis=1)\n",
    "        tk_season[:,i,j] = np.nanmean(tk_grouping,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-religion",
   "metadata": {},
   "outputs": [],
   "source": [
    "roy_season.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-privilege",
   "metadata": {},
   "outputs": [],
   "source": [
    "seas_lon = roy_season.shape[1]\n",
    "seas_lat = roy_season.shape[2]\n",
    "\n",
    "print(seas_lon)\n",
    "print(seas_lat)\n",
    "\n",
    "season_corr = np.zeros((seas_lon,seas_lat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in our 3d array we want to create a correlation coefficient for each (x,y) pixel value\n",
    "#we can use df.corr along z axis for each (x,y) value\n",
    "\n",
    "for i in range(seas_lon):\n",
    "\n",
    "    if np.mod(i,50) == 0:\n",
    "        print((i/seas_lon)*100,'%')   \n",
    "        \n",
    "    for j in range(seas_lat):\n",
    "        \n",
    "        r_z_seas = roy_season[:,i,j] #absorption\n",
    "        t_z_seas = tk_season[:,i,j] #backscattering\n",
    "        \n",
    "        z_seas_combined = [r_z_seas,t_z_seas]\n",
    "        corr_df_seas = pd.DataFrame(z_seas_combined,index = ['roy','tk'])\n",
    "        corr_df_seas = corr_df_seas.transpose()\n",
    "        \n",
    "        season_corr[i,j] = corr_df_seas.corr().values[0,1]  \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "introductory-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "season_corr = np.transpose(season_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-egypt",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(season_corr)\n",
    "plt.colorbar()\n",
    "plt.savefig('/home/jovyan/quickplots/'+\n",
    "            'detrended_roy_tk_['\n",
    "            +str(o_l)+'-'+str(o_h)+','\n",
    "            +str(a_l)+'-'+str(a_h)+\n",
    "            '].png', dpi=600,format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmean(season_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-interstate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-while",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-yukon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-marker",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
